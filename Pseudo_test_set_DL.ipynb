{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL_p7B2lO6eM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "import random\n",
        "\n",
        "def set_seed(seed=123):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "YSqCXNvVPEIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "historical_df = pd.read_csv(\"merged_energy_weather_data.csv\", parse_dates=[\"Date\"])\n",
        "forecast_df = pd.read_csv(\"weather_forecasts_aug.csv\", parse_dates=[\"Date\"])\n",
        "actual_df = pd.read_csv(\"actual_aug.csv\", parse_dates=[\"Date\"])"
      ],
      "metadata": {
        "id": "FWnCcl_BPERc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_df.columns = [\n",
        "    \"date\", \"price\", \"temp\", \"precip\", \"wind\", \"humidity\",\n",
        "    \"cloud\", \"radiation\", \"week_day\", \"month\", \"day_month\"\n",
        "]\n",
        "print(historical_df.shape)\n",
        "print(historical_df.head())\n",
        "\n",
        "historical_df = historical_df.sort_values(\"date\").reset_index(drop=True)\n",
        "cloud_missing = historical_df['cloud'].isna()\n",
        "historical_df.loc[cloud_missing, 'cloud'] = (\n",
        "    historical_df['cloud'].shift(1) + historical_df['cloud'].shift(-1)\n",
        ") / 2\n",
        "print(\"Remaining NaNs:\\n\", historical_df.isna().sum())"
      ],
      "metadata": {
        "id": "bPVz0V8OPEYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = historical_df.copy()\n",
        "df = df.drop(columns=[\"day_month\"])\n",
        "\n",
        "df = df.sort_values(\"date\").reset_index(drop=True)\n",
        "for lag in range(1, 8):\n",
        "    df[f\"lag_{lag}\"] = df[\"price\"].shift(lag)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FsaelNMyPEaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_df.columns = [\n",
        "    \"date\", \"temp\", \"precip\", \"wind\", \"humidity\",\n",
        "    \"cloud\", \"radiation\", \"week_day\", \"month\"\n",
        "]\n",
        "print(forecast_df.shape)\n",
        "forecast_df.head()"
      ],
      "metadata": {
        "id": "sp986YlrPEc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_df.columns = [\"date\", \"price\"]\n",
        "print(actual_df.shape)\n",
        "actual_df.head()"
      ],
      "metadata": {
        "id": "Us34aJdRF550"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feedforward NN"
      ],
      "metadata": {
        "id": "q7kzZongfsSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define Feedforward NN Model\n",
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[64], dropout=0.0):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            if dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            prev_dim = hidden_dim\n",
        "        layers.append(nn.Linear(prev_dim, 1))  # Output layer\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Define feature columns (input features for the model)\n",
        "feature_cols = [\n",
        "    \"temp\", \"precip\", \"wind\", \"humidity\", \"cloud\", \"radiation\",\n",
        "    \"week_day\", \"month\",\n",
        "    \"lag_1\", \"lag_2\", \"lag_3\", \"lag_4\", \"lag_5\", \"lag_6\", \"lag_7\"\n",
        "]"
      ],
      "metadata": {
        "id": "B_aRFeupF6Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Extract input (X) and target (y) for training\n",
        "X_train = df[feature_cols].values\n",
        "y_train = df[\"price\"].values.reshape(-1, 1)\n",
        "\n",
        "# Fit scalers\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "# Initialize and train the model (best parameters)\n",
        "model_ff = FeedforwardNN(input_dim=X_train.shape[1], hidden_dims=[64], dropout=0.0).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_ff.parameters(), lr=0.001)\n",
        "\n",
        "# Simple training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model_ff.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_ff(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "kwOEhOdfP4f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a working copy of the forecast data\n",
        "final_forecast_df = forecast_df.copy()\n",
        "final_forecast_df = final_forecast_df.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "# Initialize lag window from final 7 days of training set\n",
        "lag_window = df[\"price\"].iloc[-7:].tolist()\n",
        "\n",
        "# Add placeholder lag columns\n",
        "for lag in range(1, 8):\n",
        "    final_forecast_df[f\"lag_{lag}\"] = np.nan\n",
        "\n",
        "# Fill lags for the first forecast row\n",
        "for i in range(14):\n",
        "    for lag_i in range(1, 8):\n",
        "        final_forecast_df.loc[i, f\"lag_{lag_i}\"] = lag_window[-lag_i]"
      ],
      "metadata": {
        "id": "piwgUZQxP4iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ff.eval()\n",
        "ffnn_preds = []\n",
        "\n",
        "for i in range(14):\n",
        "    row = final_forecast_df.iloc[i].copy()\n",
        "\n",
        "    # Set lag values in row from current lag_window\n",
        "    for lag_i in range(1, 8):\n",
        "        row[f\"lag_{lag_i}\"] = lag_window[-lag_i]\n",
        "\n",
        "    print(f\"\\nDay {i+1} – Current lag window:\", lag_window[::-1])\n",
        "\n",
        "    # Prepare input row\n",
        "    input_row = row[feature_cols].values.reshape(1, -1)\n",
        "    input_scaled = scaler_X.transform(input_row)\n",
        "    input_tensor = torch.tensor(input_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        pred_scaled = model_ff(input_tensor).cpu().numpy().flatten()\n",
        "        pred_price = scaler_y.inverse_transform(pred_scaled.reshape(1, -1)).flatten()[0]\n",
        "\n",
        "    print(f\"Prediction: {pred_price:.2f}\")\n",
        "\n",
        "    # Append prediction\n",
        "    ffnn_preds.append(pred_price)\n",
        "\n",
        "    # Update lag window (autoregressively)\n",
        "    lag_window.append(pred_price)\n",
        "    lag_window = lag_window[1:]"
      ],
      "metadata": {
        "id": "FboPhhLNP4km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "actual_prices = actual_df[\"price\"].values[:14]\n",
        "\n",
        "def mape(actual, predicted, eps=5):\n",
        "    \"\"\"\n",
        "    Compute a stable Mean Absolute Percentage Error (MAPE) by flooring small actual values.\n",
        "\n",
        "    Parameters:\n",
        "        actual (np.array): Actual target values\n",
        "        predicted (np.array): Predicted values\n",
        "        eps (float): Minimum denominator value to avoid exploding percentages\n",
        "\n",
        "    Returns:\n",
        "        float: MAPE percentage\n",
        "    \"\"\"\n",
        "    denom = np.maximum(np.abs(actual), eps)\n",
        "    return np.mean(np.abs(actual - predicted) / denom) * 100\n",
        "\n",
        "def smape(actual, predicted, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Compute the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
        "\n",
        "    Parameters:\n",
        "        actual (np.array): Actual values\n",
        "        predicted (np.array): Predicted values\n",
        "        eps (float): Small value to prevent division by zero\n",
        "\n",
        "    Returns:\n",
        "        float: SMAPE percentage\n",
        "    \"\"\"\n",
        "    actual = np.array(actual)\n",
        "    predicted = np.array(predicted)\n",
        "\n",
        "    denominator = (np.abs(actual) + np.abs(predicted)) + eps\n",
        "    smape_val = np.mean(2 * np.abs(predicted - actual) / denominator) * 100\n",
        "    return smape_val\n",
        "\n",
        "mae = mean_absolute_error(actual_prices, ffnn_preds)\n",
        "mse = mean_squared_error(actual_prices, ffnn_preds)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "mape_value = mape(actual_prices, ffnn_preds)\n",
        "smape_val = smape(actual_prices, ffnn_preds)\n",
        "\n",
        "print(\"\\n Feedforward NN – Pseudo-Test Evaluation:\")\n",
        "print(f\"MAE:  {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAPE: {mape_value:.4f}\")\n",
        "print(f\"SMAPE: {smape_val:.4f}\")"
      ],
      "metadata": {
        "id": "teoPGdD5P4mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(actual_prices)"
      ],
      "metadata": {
        "id": "NEWaBh8VF6E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(actual_prices, label=\"Actual\")\n",
        "plt.plot(ffnn_preds, label=\"Predicted\", linestyle='--')\n",
        "plt.title(\"Feedforward NN – Pseudo-Test Predictions\")\n",
        "plt.xlabel(\"Day (1–14 Aug)\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LehKmfRVMNnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (true, pred) in enumerate(zip(actual_prices, ffnn_preds)):\n",
        "    print(f\"Day {i+1}: Actual={true:.2f}, Predicted={pred:.2f}\")"
      ],
      "metadata": {
        "id": "kxQUo54bMNp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCN"
      ],
      "metadata": {
        "id": "jnK9KF6QfyRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super().__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size]  # crop from the end only\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "            self.conv2, self.chomp2, self.relu2, self.dropout2\n",
        "        )\n",
        "\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) \\\n",
        "            if in_channels != out_channels else None\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, num_inputs, output_size, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            in_ch = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_ch = num_channels[i]\n",
        "            dilation_size = 2 ** i\n",
        "            padding = (kernel_size - 1) * dilation_size\n",
        "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=padding, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, seq_len, features] -> [batch, features, seq_len]\n",
        "        x = x.permute(0, 2, 1)\n",
        "        y = self.network(x)\n",
        "        # Take the last time step's output\n",
        "        y = y[:, :, -1]\n",
        "        return self.linear(y)"
      ],
      "metadata": {
        "id": "kcfLkJ-IUxm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best hyperparameters\n",
        "channels = [128, 128]\n",
        "kernel_size = 5\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "batch_size = 32\n",
        "sequence_len = 30\n",
        "horizon = 14\n",
        "\n",
        "# Input/output sizes\n",
        "input_size = df.drop(columns=[\"price\", \"date\"]).shape[1]\n",
        "output_size = 1\n",
        "\n",
        "# Reinitialize model with the updated TCN definition\n",
        "model_tcn = TCN(num_inputs=input_size, output_size=output_size, num_channels=channels,\n",
        "                kernel_size=kernel_size, dropout=dropout).to(device)\n",
        "\n",
        "# Re-train the model on full data\n",
        "X_full = df.drop(columns=[\"price\", \"date\"]).values\n",
        "y_full = df[\"price\"].values.reshape(-1, 1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X_full)\n",
        "y_scaled = scaler_y.fit_transform(y_full)\n",
        "\n",
        "# Create input sequences for training\n",
        "def create_tcn_sequences(X, y, sequence_len):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - sequence_len):\n",
        "        X_seq.append(X[i:i+sequence_len])\n",
        "        y_seq.append(y[i+sequence_len])\n",
        "    return torch.tensor(X_seq, dtype=torch.float32), torch.tensor(y_seq, dtype=torch.float32)\n",
        "\n",
        "X_train_tcn, y_train_tcn = create_tcn_sequences(X_scaled, y_scaled, sequence_len)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tcn, y_train_tcn)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Optimizer and loss\n",
        "optimizer = torch.optim.Adam(model_tcn.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Train for fixed epochs\n",
        "model_tcn.train()\n",
        "for epoch in range(50):\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model_tcn(xb).squeeze()\n",
        "        loss = criterion(preds, yb.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "ZWYN5msLfxfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting inputs\n",
        "last_rows = df.drop(columns=[\"price\", \"date\"]).iloc[-sequence_len:].copy()\n",
        "lag_window = df[\"price\"].iloc[-7:].tolist()\n",
        "\n",
        "tcn_preds = []\n",
        "\n",
        "for i in range(14):  # Day 1 to 14 August\n",
        "    row = forecast_df.iloc[i].copy()\n",
        "\n",
        "    # Insert lag values into the row\n",
        "    for lag_i in range(1, 8):\n",
        "        row[f\"lag_{lag_i}\"] = lag_window[-lag_i]\n",
        "\n",
        "    # Combine with previous sequence\n",
        "    input_seq = pd.concat([last_rows.iloc[1:], row.to_frame().T], ignore_index=True)\n",
        "    last_rows = input_seq.copy()\n",
        "\n",
        "    # Scale and predict\n",
        "    X_input = scaler_X.transform(input_seq.drop(columns=[\"date\"]).values).reshape(1, sequence_len, -1)\n",
        "    X_tensor = torch.tensor(X_input, dtype=torch.float32).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_scaled = model_tcn(X_tensor).cpu().numpy().flatten()[0]\n",
        "        pred_price = scaler_y.inverse_transform([[pred_scaled]])[0, 0]\n",
        "\n",
        "    tcn_preds.append(pred_price)\n",
        "    lag_window.append(pred_price)\n",
        "    lag_window = lag_window[1:]"
      ],
      "metadata": {
        "id": "XpoVqkuafxh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_prices = actual_df[\"price\"].values[:14]\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    return np.mean(np.abs(y_true - y_pred) / np.maximum(denom, 5)) * 100\n",
        "\n",
        "def mape_stable(y_true, y_pred, eps=5):\n",
        "    denom = np.maximum(np.abs(y_true), eps)\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom) * 100\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "mae = mean_absolute_error(actual_prices, tcn_preds)\n",
        "rmse = np.sqrt(mean_squared_error(actual_prices, tcn_preds))\n",
        "mape = mape_stable(actual_prices, tcn_preds)\n",
        "smape_val = smape(actual_prices, tcn_preds)\n",
        "\n",
        "print(\"\\n TCN – Pseudo-Test Evaluation:\")\n",
        "print(f\"MAE:   {mae:.4f}\")\n",
        "print(f\"RMSE:  {rmse:.4f}\")\n",
        "print(f\"MAPE:  {mape:.4f}\")\n",
        "print(f\"SMAPE: {smape_val:.4f}\")\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(actual_prices, label=\"Actual\")\n",
        "plt.plot(tcn_preds, label=\"Predicted\", linestyle='--')\n",
        "plt.title(\"TCN – Pseudo-Test Predictions\")\n",
        "plt.xlabel(\"Day (1–14 Aug)\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hOmNojoShroy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot of actual prices vs. FFNN predictions vs. TCN predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(actual_prices, label=\"Actual\", marker='o')\n",
        "plt.plot(ffnn_preds, label=\"Feedforward NN\", linestyle='--', marker='s')\n",
        "plt.plot(tcn_preds, label=\"TCN\", linestyle='--', marker='^')\n",
        "\n",
        "plt.title(\"Pseudo-Test Predictions (1–14 August 2025)\")\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Energy Price\")\n",
        "plt.xticks(ticks=np.arange(14), labels=np.arange(1, 15))\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1I7NsFtwz6Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t28EzBQqJG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LHJUTGgqJa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLEnJpi2y8gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wk-752Rwy-oH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}